{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyKyr/CompIntel-Projects/blob/main/GAs2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bmoCnFci59fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log2\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WTdMg9za6J32"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dataMatrix = None\n",
        "        self.labels = None\n",
        "        self.size = None\n",
        "\n",
        "    def getLexicalSize(self,file):\n",
        "        lexiconS = []\n",
        "        with open(file, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                lexiconS.append(line.split()[0])\n",
        "        return  len(lexiconS)\n",
        "    def getLabels(self,data):\n",
        "        self.labels = []\n",
        "        with open(data, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                self.labels.append([int(i) for i in line.split()])\n",
        "\n",
        "    def getData(self,data,lexicon):\n",
        "        bagof = []\n",
        "        bagofcsr =[]\n",
        "        with open(data,\"r\") as fp:\n",
        "            for line in fp:\n",
        "                vertex = [0 for i in range(self.getLexicalSize(lexicon))]\n",
        "                array = list(filter(lambda x : x[0] != '<' , line.split()))\n",
        "                for ele in array:\n",
        "                    vertex[int(ele)] +=1\n",
        "                self.size = len(vertex)\n",
        "                bagof.append(vertex)\n",
        "        return bagof\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hyY2YfnF6Lce"
      },
      "outputs": [],
      "source": [
        "\n",
        "datalex = Parser()\n",
        "\n",
        "\n",
        "bagofwords = datalex.getData(\"/drive/MyDrive/ML/train-data.dat\",\"/drive/MyDrive/ML/vocabs.txt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrmR3k47r6d4"
      },
      "outputs": [],
      "source": [
        "from os import WCOREDUMP\n",
        "class Individual(object):\n",
        "    def __init__(self, chromosome):\n",
        "        self.chromosome = chromosome\n",
        "        \n",
        "\n",
        "    @classmethod\n",
        "    def create_genome(self):\n",
        "\n",
        "        genome = np.random.randint(0, 1, size=8520)\n",
        "        rand_ones = random.randint(0, 8519)\n",
        "        for _ in range(rand_ones):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        return genome\n",
        "\n",
        "    def calculate_fitness(self):\n",
        "        return 0\n",
        "\n",
        "\n",
        "def genome_rejection(genome: Individual):\n",
        "    # replace the non valid genome\n",
        "    # TODO recursion\n",
        "    while np.count_nonzero(genome) < 1000:\n",
        "        genome = Individual.create_genome()\n",
        "    return genome\n",
        "\n",
        "\n",
        "def repair_genome(genome: Individual):\n",
        "    nnz = np.count_nonzero(genome)\n",
        "    while nnz < 1000:\n",
        "        difference = 1000 - nnz\n",
        "        for _ in range(difference):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        nnz = np.count_nonzero(genome)\n",
        "    return genome\n",
        "\n",
        "def initialize_population(no_of_chromosomes):\n",
        "    population = []\n",
        "    for _ in range(no_of_chromosomes):\n",
        "        genome = Individual.create_genome()\n",
        "        # genome = genome_rejection(genome)\n",
        "        genome = repair_genome(genome)\n",
        "        population.append(Individual(genome))\n",
        "\n",
        "    return population\n",
        "\n",
        "\n",
        "def fitnessFunc(population:Individual,tfidf):\n",
        "  #Calculating the fittest with the best sum of avg in tf_idf\n",
        "  #Sort population by nonzero\n",
        "  population.sort(key = lambda x:np.count_nonzero(x.chromosome))\n",
        "  significance = [0 for _ in range(len(population))]\n",
        "\n",
        "  for i,individual in enumerate(population):\n",
        "    for value in np.nonzero(individual.chromosome)[0]:\n",
        "      significance[i] += tfidf[value]\n",
        "      \n",
        "  return significance\n",
        "\n",
        "\n",
        "def tf_idf(bagofwords,verbose=0):\n",
        "  count=0\n",
        "  N=len(bagofwords)\n",
        "  n = len(bagofwords[0])\n",
        "  tfbag = []\n",
        "  \n",
        "  textDCount = np.count_nonzero(bagofwords,axis=0)  #word count of the text body\n",
        "  worddcount = np.count_nonzero(bagofwords,axis=1) #word count for each text\n",
        "  \n",
        "  #----------------IDF----------------------\n",
        "  _idf = [0 for _ in range(len(textDCount))]\n",
        "  tf_idf= []\n",
        "  for k,value in enumerate(textDCount):\n",
        "    _idf[k] = np.log10(N/value)\n",
        "  _idf = np.array(_idf)\n",
        "  #---------------TF-----------------------\n",
        "  tfDict = [0 for _ in range(N)]\n",
        "  for i in range(N):\n",
        "    count+=1\n",
        "    tfDict[i] = np.array([(text/worddcount[i]) for k,text in enumerate(bagofwords[i])])\n",
        "    if verbose==1:\n",
        "      print(\"======================================\")\n",
        "      print(\"Finished\",count,\"st\",\"Calculation\")\n",
        "  \n",
        "  tfDict = np.array(tfDict)\n",
        "  \n",
        "  \n",
        "  for ele in tfDict:\n",
        "    tf_idf.append(ele*_idf)\n",
        "  \n",
        "  avg = np.mean(tf_idf, axis = 0)\n",
        "  return avg\n",
        " \n",
        "\n",
        "\n",
        "  \n",
        "   \n",
        "\n",
        "tf__idf = tf_idf(bagofwords)\n",
        "population = initialize_population(10)\n",
        "fitness = fitnessFunc(population,tf__idf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9fIhqodQZCc3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}