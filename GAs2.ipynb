{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyKyr/CompIntel-Projects/blob/main/GAs2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bmoCnFci59fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log2\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WTdMg9za6J32"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dataMatrix = None\n",
        "        self.labels = None\n",
        "        self.size = None\n",
        "\n",
        "    def getLexicalSize(self,file):\n",
        "        lexiconS = []\n",
        "        with open(file, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                lexiconS.append(line.split()[0])\n",
        "        return  len(lexiconS)\n",
        "    def getLabels(self,data):\n",
        "        self.labels = []\n",
        "        with open(data, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                self.labels.append([int(i) for i in line.split()])\n",
        "\n",
        "    def getData(self,data,lexicon):\n",
        "        bagof = []\n",
        "        bagofcsr =[]\n",
        "        with open(data,\"r\") as fp:\n",
        "            for line in fp:\n",
        "                vertex = [0 for i in range(self.getLexicalSize(lexicon))]\n",
        "                array = list(filter(lambda x : x[0] != '<' , line.split()))\n",
        "                for ele in array:\n",
        "                    vertex[int(ele)] +=1\n",
        "                self.size = len(vertex)\n",
        "                bagofcsr.append(sparse.csr_matrix(vertex))\n",
        "                bagof.append(vertex)\n",
        "        return bagof,bagofcsr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hyY2YfnF6Lce"
      },
      "outputs": [],
      "source": [
        "\n",
        "datalex = Parser()\n",
        "\n",
        "\n",
        "bagofwords,bagofcsr = datalex.getData(\"/drive/MyDrive/ML/train-data.dat\",\"/drive/MyDrive/ML/vocabs.txt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tell = np.count_nonzero(bagofwords,axis=0)\n",
        "   \n",
        "    \n",
        "tell2 = np.count_nonzero(bagofwords,axis=1)"
      ],
      "metadata": {
        "id": "LBjvkfX0MA4f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrmR3k47r6d4"
      },
      "outputs": [],
      "source": [
        "class Individual(object):\n",
        "    def __init__(self, chromosome):\n",
        "        self.chromosome = chromosome\n",
        "        self.fitness = self.calculate_fitness()\n",
        "\n",
        "    @classmethod\n",
        "    def create_genome(self):\n",
        "\n",
        "        genome = np.random.randint(0, 1, size=8520)\n",
        "        rand_ones = random.randint(0, 8519)\n",
        "        for _ in range(rand_ones):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        return genome\n",
        "\n",
        "    def calculate_fitness(self):\n",
        "        return 0\n",
        "\n",
        "\n",
        "def genome_rejection(genome: Individual):\n",
        "    # replace the non valid genome\n",
        "    # TODO recursion\n",
        "    while np.count_nonzero(genome) < 1000:\n",
        "        genome = Individual.create_genome()\n",
        "    return genome\n",
        "\n",
        "\n",
        "def repair_genome(genome: Individual):\n",
        "    nnz = np.count_nonzero(genome)\n",
        "    while nnz < 1000:\n",
        "        difference = 1000 - nnz\n",
        "        for _ in range(difference):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        nnz = np.count_nonzero(genome)\n",
        "    return genome\n",
        "def initialize_population(no_of_chromosomes):\n",
        "    population = []\n",
        "    for _ in range(no_of_chromosomes):\n",
        "        genome = Individual.create_genome()\n",
        "        # genome = genome_rejection(genome)\n",
        "        genome = repair_genome(genome)\n",
        "        population.append(genome)\n",
        "\n",
        "    return np.array(population)\n",
        "\n",
        "def BinarySearch(content:list,left,right,number):\n",
        "  median = (right+left)//2\n",
        "\n",
        "  if right >= left:\n",
        "    if content[median]==number:\n",
        "      return median\n",
        "    if content[median]>number:\n",
        "      return BinarySearch(content,left,median-1,number)\n",
        "    else:\n",
        "      return BinarySearch(content,median+1,right,number)\n",
        "  else:\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "def tf_idf(t,D,tcountd,lengthofD):\n",
        "  #calculate tf\n",
        "    count =0\n",
        "    \n",
        "    N = len(D)\n",
        "    tfbag = []\n",
        "    _idf = [0 for _ in range(len(tcountd))]\n",
        "    print(len(_idf))\n",
        "    tf_idf =[]\n",
        "    for k,value in enumerate(tcountd):\n",
        "      _idf[k] = math.log(N/value)\n",
        "    for i,ele in enumerate(t):\n",
        "      count+=1\n",
        "      tfDict = [0 for _ in range(len(t[0]))]\n",
        "      for j,value in enumerate(ele):\n",
        "        \n",
        "        \n",
        "        if value == 0:\n",
        "          tfDict[j] = 0\n",
        "        else:\n",
        "            tfDict[j] = (value/lengthofD[i])\n",
        "      tfbag.append(tfDict)\n",
        "      print(\"======================================\")\n",
        "      print(\"Finished\",count,\"st\",\"Calculation\")\n",
        "    \n",
        "    newtf = np.array(tfbag)\n",
        "    for tf,idf in zip(tfbag,_idf):\n",
        "     \n",
        "      tf_idf.append( np.dot(tf,idf))\n",
        "\n",
        "\n",
        "    return np.array(tf_idf)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    count=0\n",
        "  \n",
        "   \n",
        "    dicto = []\n",
        "      \n",
        "    dicto = tf_idf(bagofwords,bagofcsr,tell,tell2)\n",
        "\n",
        "      \n",
        "    return np.array(dicto)\n",
        "if __name__ == '__main__':\n",
        "    temp = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mo = []\n",
        "for value in temp:\n",
        "  mo.append( np.sum(value)/len(temp))"
      ],
      "metadata": {
        "id": "mx7B8bO0ES0U"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}