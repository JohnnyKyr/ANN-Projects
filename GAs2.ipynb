{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyKyr/CompIntel-Projects/blob/main/GAs2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "bmoCnFci59fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55e4f0a-81a6-4ff5-ae17-eb1b6b5dff48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log2\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "WTdMg9za6J32"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dataMatrix = None\n",
        "        self.labels = None\n",
        "        self.size = None\n",
        "\n",
        "    def getLexicalSize(self,file):\n",
        "        lexiconS = []\n",
        "        with open(file, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                lexiconS.append(line.split()[0])\n",
        "        return  len(lexiconS)\n",
        "    def getLabels(self,data):\n",
        "        self.labels = []\n",
        "        with open(data, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                self.labels.append([int(i) for i in line.split()])\n",
        "\n",
        "    def getData(self,data,lexicon):\n",
        "        bagof = []\n",
        "        bagofcsr =[]\n",
        "        with open(data,\"r\") as fp:\n",
        "            for line in fp:\n",
        "                vertex = [0 for i in range(self.getLexicalSize(lexicon))]\n",
        "                array = list(filter(lambda x : x[0] != '<' , line.split()))\n",
        "                for ele in array:\n",
        "                    vertex[int(ele)] +=1\n",
        "                self.size = len(vertex)\n",
        "                bagof.append(vertex)\n",
        "        return bagof\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "hyY2YfnF6Lce"
      },
      "outputs": [],
      "source": [
        "\n",
        "datalex = Parser()\n",
        "\n",
        "\n",
        "bagofwords = datalex.getData(\"/drive/MyDrive/ML/train-data.dat\",\"/drive/MyDrive/ML/vocabs.txt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "qrmR3k47r6d4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tf_idf(bagofwords,verbose=0):\n",
        "  count=0\n",
        "  N=len(bagofwords)\n",
        "  n = len(bagofwords[0])\n",
        "  tfbag = []\n",
        "  \n",
        "  textDCount = np.count_nonzero(bagofwords,axis=0)  #word count of the text body\n",
        "  worddcount = np.count_nonzero(bagofwords,axis=1) #word count for each text\n",
        "  \n",
        "  #----------------IDF----------------------\n",
        "  _idf = [0 for _ in range(len(textDCount))]\n",
        "  tf_idf= []\n",
        "  for k,value in enumerate(textDCount):\n",
        "    _idf[k] = np.log10(N/value)\n",
        "  _idf = np.array(_idf)\n",
        "  #---------------TF-----------------------\n",
        "  tfDict = [0 for _ in range(N)]\n",
        "  for i in range(N):\n",
        "    count+=1\n",
        "    tfDict[i] = np.array([(text/worddcount[i]) for k,text in enumerate(bagofwords[i])])\n",
        "    if verbose==1:\n",
        "      print(\"======================================\")\n",
        "      print(\"Finished\",count,\"st\",\"Calculation\")\n",
        "  \n",
        "  tfDict = np.array(tfDict)\n",
        "  \n",
        "  \n",
        "  for ele in tfDict:\n",
        "    tf_idf.append(ele*_idf)\n",
        "  \n",
        "  avg = np.mean(tf_idf, axis = 0)\n",
        "  return avg\n",
        "   \n",
        "\n",
        "tf__idf = tf_idf(bagofwords)\n",
        "\n",
        "maximum = 0\n",
        "for ele in tf__idf:\n",
        "  maximum+=ele"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Individual(object):\n",
        "    def __init__(self, chromosome):\n",
        "        self.chromosome = chromosome\n",
        "        self.fitness = 0\n",
        "\n",
        "    @classmethod\n",
        "    def create_genome(self):\n",
        "\n",
        "        genome = np.random.randint(0, 1, size=8520)\n",
        "        rand_ones = random.randint(0, 8519)\n",
        "        for _ in range(rand_ones):\n",
        "          index = random.randint(0, 8519)\n",
        "          while genome[index] == 1:\n",
        "            index = random.randint(0, 8519)\n",
        "          else:\n",
        "            genome[index] = 1\n",
        "        return genome\n",
        "\n",
        "    def calculate_fitness(self):\n",
        "        return 0\n",
        "\n",
        "\n",
        "def genome_rejection(genome: Individual):\n",
        "    # replace the non valid genome\n",
        "    # TODO recursion\n",
        "    while np.count_nonzero(genome) < 1000:\n",
        "        genome = Individual.create_genome()\n",
        "    return genome\n",
        "\n",
        "\n",
        "def repair_genome(genome: Individual):\n",
        "    nnz = np.count_nonzero(genome)\n",
        "    while nnz < 1000:\n",
        "        difference = 1000 - nnz\n",
        "        for _ in range(difference):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        nnz = np.count_nonzero(genome)\n",
        "    return genome\n",
        "\n",
        "def initialize_population(no_of_chromosomes):\n",
        "    population = []\n",
        "    for _ in range(no_of_chromosomes):\n",
        "        genome = Individual.create_genome()\n",
        "        # genome = genome_rejection(genome)\n",
        "        genome = repair_genome(genome)\n",
        "        population.append(Individual(genome))\n",
        "\n",
        "    return population\n",
        "\n",
        "\n",
        "def fitnessFunc(population:Individual,tfidf):\n",
        "  #Calculating the fittest with the best sum of avg in tf_idf\n",
        "  #Sort population by nonzero\n",
        "  global maximum\n",
        "\n",
        "  for i,individual in enumerate(population):\n",
        "    for value in np.nonzero(individual.chromosome)[0]:\n",
        "      individual.fitness += tfidf[value]\n",
        "\n",
        "    if np.count_nonzero(individual.chromosome)>2000:\n",
        "      per = (np.count_nonzero(individual.chromosome)//100)/100\n",
        "      individual.fitness -=per*maximum\n",
        "  \n",
        "  \n",
        "\n",
        "def RouleteWheelSelection(population):\n",
        "  \n",
        "  s=0\n",
        "\n",
        "  population_fitness = sum([individual.fitness for individual in population])\n",
        "  r = random.randint(0, int(population_fitness))\n",
        "  prob = [individual.fitness/population_fitness for individual in population]\n",
        "  \n",
        "  for individual in population:\n",
        "    s+=individual.fitness\n",
        "    if s>=r:\n",
        "      return individual\n",
        "\n",
        "def TournamentSelection(population):\n",
        "  K =  random.randint(1, len(population))\n",
        "  k_individuals = []\n",
        "  for _ in range(K):\n",
        "    k_individuals.append(population[random.randint(0, len(population)-1)])\n",
        "  k_individuals.sort(key = lambda x:x.fitness)\n",
        "\n",
        "  return k_individuals[-1]\n",
        "\n",
        "def Crossover(parent1,parent2,k=2):\n",
        "  points = [np.random.randint(0,len(parent1.chromosome)) for _ in range(k)]\n",
        "  points.sort()\n",
        "  \n",
        "  for i in points:\n",
        "    A=np.append(parent1.chromosome[:i],parent2.chromosome[i:])\n",
        "    B=np.append(parent2.chromosome[:i],parent1.chromosome[i:])\n",
        "  return Individual(A),Individual(B)\n",
        "\n",
        "def Repetition(old,new,rpgenome):\n",
        "\n",
        "  if old:\n",
        "    if np.array_equal(old.chromosome,new.chromosome):\n",
        "      rpgenome +=1\n",
        "    \n",
        "    if new.fitness > old.fitness:\n",
        "      old = new\n",
        "      rpgenome=1\n",
        "  else:\n",
        "    old = new\n",
        "  return rpgenome,old\n",
        "\n",
        "def Main():\n",
        "  POPULATION_SIZE = 100\n",
        "  generations = 0\n",
        "  end = False\n",
        "  population = initialize_population(POPULATION_SIZE)\n",
        "  best_individual = None\n",
        "  new_best = None\n",
        "  \n",
        "  repeated_genome = 0\n",
        "  while not end:\n",
        "\n",
        "    if generations==1000:\n",
        "      end = True\n",
        "\n",
        "    \n",
        "    \n",
        "    if repeated_genome >=50:\n",
        "      end=True\n",
        "      print(\"Interrupt after repitition\")\n",
        "\n",
        "    fitnessFunc(population,tf__idf)\n",
        "\n",
        "    new_generation = []\n",
        "    population = sorted(population, key = lambda x:x.fitness)\n",
        "    \n",
        "    new_best = population[-1]\n",
        "\n",
        "    repeated_genome,best_individual = Repetition(best_individual,new_best,repeated_genome)\n",
        "\n",
        "    s = int((10*POPULATION_SIZE)/100)\n",
        "    new_generation.extend(population[:s])\n",
        "    \n",
        "    for _ in range((POPULATION_SIZE-s)//2):\n",
        "      parent1 = TournamentSelection(population)\n",
        "      parent2 = TournamentSelection(population)\n",
        "      offspring1,offspring2 = Crossover(parent1,parent2)\n",
        "      new_generation.append(offspring1)\n",
        "      new_generation.append(offspring2)\n",
        "    \n",
        "    print(\"Generation:\",generations,\"Best_individual:\",best_individual.fitness)\n",
        "    population = new_generation\n",
        "    generations+=1\n",
        "\n"
      ],
      "metadata": {
        "id": "XgV7tGVgU028"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "if __name__ == \"__main__\":\n",
        "  Main() "
      ],
      "metadata": {
        "id": "9fIhqodQZCc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GYLGX0zD2cmy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GAs2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}