{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyKyr/ANN-Projects/blob/main/GAs2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bmoCnFci59fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log2\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WTdMg9za6J32"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dataMatrix = None\n",
        "        self.labels = None\n",
        "        self.size = None\n",
        "\n",
        "    def getLexicalSize(self,file):\n",
        "        lexiconS = []\n",
        "        with open(file, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                lexiconS.append(line.split()[0])\n",
        "        return  len(lexiconS)\n",
        "    def getLabels(self,data):\n",
        "        self.labels = []\n",
        "        with open(data, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                self.labels.append([int(i) for i in line.split()])\n",
        "\n",
        "    def getData(self,data,lexicon):\n",
        "        bagof = []\n",
        "        with open(data,\"r\") as fp:\n",
        "            for line in fp:\n",
        "                vertex = [0 for i in range(self.getLexicalSize(lexicon))]\n",
        "                array = list(filter(lambda x : x[0] != '<' , line.split()))\n",
        "                for ele in array:\n",
        "                    vertex[int(ele)] +=1\n",
        "                self.size = len(vertex)\n",
        "                bagof.append(sparse.csr_matrix(vertex))\n",
        "        return bagof\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hyY2YfnF6Lce"
      },
      "outputs": [],
      "source": [
        "\n",
        "datalex = Parser()\n",
        "\n",
        "\n",
        "bagofwords = datalex.getData(\"/drive/MyDrive/ML/train-data.dat\",\"/drive/MyDrive/ML/vocabs.txt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrmR3k47r6d4",
        "outputId": "4f62aee4-0d9a-42e2-afb1-f256bf63d383"
      },
    
      "source": [
        "class Individual(object):\n",
        "    def __init__(self, chromosome):\n",
        "        self.chromosome = chromosome\n",
        "        self.fitness = self.calculate_fitness()\n",
        "\n",
        "    @classmethod\n",
        "    def create_genome(self):\n",
        "\n",
        "        genome = np.random.randint(0, 1, size=8520)\n",
        "        rand_ones = random.randint(0, 8519)\n",
        "        for _ in range(rand_ones):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        return genome\n",
        "\n",
        "    def calculate_fitness(self):\n",
        "        return 0\n",
        "\n",
        "\n",
        "def genome_rejection(genome: Individual):\n",
        "    # replace the non valid genome\n",
        "    # TODO recursion\n",
        "    while np.count_nonzero(genome) < 1000:\n",
        "        genome = Individual.create_genome()\n",
        "    return genome\n",
        "\n",
        "\n",
        "def repair_genome(genome: Individual):\n",
        "    nnz = np.count_nonzero(genome)\n",
        "    while nnz < 1000:\n",
        "        difference = 1000 - nnz\n",
        "        for _ in range(difference):\n",
        "            genome[random.randint(0, 8519)] = 1\n",
        "        nnz = np.count_nonzero(genome)\n",
        "    return genome\n",
        "\n",
        "\n",
        "def BinarySearch(content:list,left,right,number):\n",
        "  median = (right+left)//2\n",
        "\n",
        "  if right >= left:\n",
        "    if content[median]==number:\n",
        "      return median\n",
        "    if content[median]>number:\n",
        "      return BinarySearch(content,left,median-1,number)\n",
        "    else:\n",
        "      return BinarySearch(content,median+1,right,number)\n",
        "  else:\n",
        "    return\n",
        "\n",
        "\n",
        "def idf(t,D):\n",
        "  count = 1\n",
        "  N  = len(D)\n",
        "  for ele in D:\n",
        "      bsmot = BinarySearch(ele.indices,0,len(ele.indices)-1,t)\n",
        "      if not bsmot:\n",
        "          continue\n",
        "\n",
        "      count+=1\n",
        "\n",
        "  return math.log(N/count)\n",
        "\n",
        "def tf_idf(t,D):\n",
        "  #calculate tf\n",
        "    count =1\n",
        "    tfDict = [0 for _ in D]\n",
        "    N = len(D)\n",
        "\n",
        "    for i,ele in enumerate(D):\n",
        "      bsmot = BinarySearch(ele.indices,0,len(ele.indices)-1,t)\n",
        "      if not bsmot:\n",
        "        continue\n",
        "      else:\n",
        "          count+=1\n",
        "          tfDict[i] = (ele.data[bsmot]/sum(ele.data))\n",
        "    _idf = math.log(N/count)\n",
        "    for i,ele in enumerate(tfDict):\n",
        "        tfDict[i] = ele*_idf\n",
        "\n",
        "\n",
        "    return tfDict\n",
        "\n",
        "def initialize_population(no_of_chromosomes):\n",
        "    population = []\n",
        "    for _ in range(no_of_chromosomes):\n",
        "        genome = Individual.create_genome()\n",
        "        # genome = genome_rejection(genome)\n",
        "        genome = repair_genome(genome)\n",
        "        population.append(genome)\n",
        "\n",
        "    return np.array(population)\n",
        "\n",
        "\n",
        "def main():\n",
        "    count=0\n",
        "\n",
        "    dicto = []\n",
        "    print(initialize_population(10))\n",
        "    for i in range(datalex.size):\n",
        "      count+=1\n",
        "      dicto.append(tf_idf(i,bagofwords))\n",
        "\n",
        "      print(\"======================================\")\n",
        "      print(\"Finished\",count,\"st\",\"Calculation\")\n",
        "    return dicto\n",
        "if __name__ == '__main__':\n",
        "    temp = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4lNJgEpT-lo"
      },
      "outputs": [],
      "source": [
        "print(datalex.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMclAFU5UCtm"
      },
      "outputs": [],
      "source": [
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VjDt41I3OB_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
